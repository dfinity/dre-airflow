#!/bin/bash
set -eEuo pipefail

SCRIPT_DIR=$( cd -- "$( dirname -- "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )
VENV_DIR=$( dirname "$SCRIPT_DIR" )/venv
VENV_BIN_DIR="$VENV_DIR"/bin
export AIRFLOW_HOME=$( dirname "$SCRIPT_DIR" )/airflow
export PYTHONPATH=$(dirname "$SCRIPT_DIR")/shared
AIRFLOW_BIN="$VENV_BIN_DIR"/airflow
ONEPASS_BIN="$VENV_BIN_DIR"/1pass

export AIRFLOW__CORE__ALLOWED_DESERIALIZATION_CLASSES_REGEXP="(dfinity|airflow).*"
export AIRFLOW__WEBSERVER__ALLOW_RAW_HTML_DESCRIPTIONS=true
export PATH="$VENV_BIN_DIR:$PATH"

function install_1pass_cli() {
    if [ -x "$ONEPASS_BIN" ]; then
        return 0
    fi
    if [[ "$(uname)" == "Linux" ]]; then
        case "$(uname -m)" in
            i386) ARCH="386" ;;
            x86_64) ARCH="amd64" ;;
            armv7l) ARCH="arm" ;;
            aarch64) ARCH="arm64" ;;
            *) echo "Unsupported architecture"; exit 1 ;;
        esac && \
        wget "https://cache.agilebits.com/dist/1P/op2/pkg/v2.30.3/op_linux_${ARCH}_v2.30.3.zip" -O op.zip && \
        unzip -d op op.zip && \
        mv op/op "$VENV_BIN_DIR"/1pass && \
        rm -r op.zip op && \
        chmod 0755 "$VENV_BIN_DIR"/1pass && \
        ln -sf 1pass "$VENV_BIN_DIR"/op
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        brew install --cask 1password-cli
    fi
}

function login_1pass() {
    "$ONEPASS_BIN" whoami || {
        "$ONEPASS_BIN" account add --address dfinity.1password.com
        eval $("$ONEPASS_BIN" signin)
    }
}

function setup_airflow_variables_and_connections() {
    "$AIRFLOW_BIN" variables set "dfinity.ic_admin.mainnet.proposer_key_file" "$("$ONEPASS_BIN" read "op://DRE Team/DFX release-automation principal key/identity.pem")"
    SLACK_CREDS="$("$ONEPASS_BIN" read "op://DRE Team/Slack token for Airflow connection slack.ic_os_rollout/credential")"
    "$AIRFLOW_BIN" connections delete "slack.ic_os_rollout" || true
    "$AIRFLOW_BIN" connections add "slack.ic_os_rollout" --conn-type slack --conn-password "$SLACK_CREDS" --conn-extra "{\"slack_token\": \"$SLACK_CREDS\"}"
    GOOGLE_CREDS="$("$ONEPASS_BIN" read "op://DRE Team/Airflow Google Drive credentials/credential" | jq -c .)"
    "$AIRFLOW_BIN" connections delete "google_cloud_default" || true
    "$AIRFLOW_BIN" connections add "google_cloud_default" --conn-type google_cloud_platform --conn-extra "{
        \"extra__google_cloud_platform__project\": \"airflow-422113\",
        \"extra__google_cloud_platform__scope\": \"https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/spreadsheets\",
        \"extra__google_cloud_platform__keyfile_dict\": $GOOGLE_CREDS}
    "
}

if [ "$1" == "setup" ]
then
    # TODO: Should add a check to see if we are using a correct version of python
    # If using version >3.12 some of the packages are reported as yanked and thus
    # the script breaks.
    /usr/bin/python3 -m venv "$VENV_DIR"
    "$VENV_DIR"/bin/pip3 install "apache-airflow[celery]==2.9.1" \
        apache-airflow-providers-slack[common.sql] \
        apache-airflow-providers-google \
        --constraint https://raw.githubusercontent.com/apache/airflow/constraints-2.9.1/constraints-3.11.txt
    mkdir -p "$AIRFLOW_HOME"
    if ! test -f "$AIRFLOW_HOME"/airflow.db
    then
        PATH="$VENV_DIR/bin:$PATH" "$VENV_DIR"/bin/airflow db init
    else
        PATH="$VENV_DIR/bin:$PATH" "$VENV_DIR"/bin/airflow db migrate
    fi
    pushd "$AIRFLOW_HOME"
    ln -sfT ../dags dags
    ln -sfT ../plugins plugins
    sed -i 's/reload_on_plugin_change.*/reload_on_plugin_change = True/' airflow.cfg
    sed -i 's/load_examples.*/load_examples = False/' airflow.cfg
    popd

    # If running in an interactive shell, ask the user if they want to set up Airflow variables and connections
    read -p "Do you want to set up Airflow variables and connections (optional for most local runs)? (y/n): " setup_choice < /dev/tty || setup_choice="n"
    if [[ "$setup_choice" == "y" || "$setup_choice" == "Y" ]]; then
        install_1pass_cli
        login_1pass
        setup_airflow_variables_and_connections
    else
        echo "Skipping Airflow variables and connections setup."
    fi
fi

test -x "$VENV_DIR"/bin/airflow || {
    echo "The Airflow virtual environment is not set up at $VENV_DIR" >&2
    echo "Run this command with 'setup' as its only argument to set it up." >&2
    exit 32
}
test -f "$AIRFLOW_HOME"/airflow.cfg || {
    echo "Airflow has not been initialized at $AIRFLOW_HOME" >&2
    echo "Run this command with 'setup' as its only argument to initialize it." >&2
    exit 32
}

if [ "$1" == "check-setup" ]
then
    exit
fi

if [ "$1" == "setup" ]
then
    echo "Airflow is now successfully setup." >&2
    PATH="$VENV_DIR/bin:$PATH" "$VENV_DIR"/bin/airflow info >&2
    echo "You can now run this command with 'standalone' as its only argument." >&2
    echo "When you do that, note the admin password in the scrollback buffer -- you will need it to log in." >&2
    exit
fi

if [ "$1" == "standalone" ]
then
if pgrep -f "venv/bin/airflow" > /dev/null
then
    echo "Another instance of Airflow is already running. Please terminate it or kill airflow processes to avoid database corruption." >&2
    echo "Process IDs of running Airflow instances:" >&2
    pgrep -f "venv/bin/airflow" >&2
    exit 1
fi
fi

if [ "$1" == "unlockdb" ] || [ "$1" == "standalone" ]
then
    cd "$AIRFLOW_HOME"
    echo .dump | sqlite3 airflow.db | sqlite3 airflow.db-new
    mv -f airflow.db-new airflow.db
    echo "Database is now unlocked." >&2
    if [ "$1" == "unlockdb" ]
    then
        exit
    fi
fi

exec "$AIRFLOW_BIN" "$@"
